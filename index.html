<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Medium as Operator: Ritual vs System Presentation</title>
    <style>
        :root {
            --accent-color: #111111;
            --text-color: #333;
            --background-color: #f9f9f9;
            --slide-background: #ffffff;
            --border-color: #e0e0e0;
            --ritual-color-bg: #fff0dc; /* Light peach for background */
            --ritual-color-text: #8B4513; /* SaddleBrown for text emphasis */
            --system-color-bg: #dceefc; /* Light sky blue for background */
            --system-color-text: #1E90FF; /* DodgerBlue for text emphasis */
            --highlight-color: #fff9e6; /* Very light yellow for notes */
            --font-family-primary: 'Helvetica Neue', Helvetica, Arial, sans-serif;
            --font-family-secondary: 'Georgia', serif; /* For more evocative text perhaps */
        }

        html, body {
            height: 100%;
            width: 100%;
            margin: 0;
            overflow: hidden; /* Prevent scrolling the entire document */
            font-family: var(--font-family-primary);
            line-height: 1.6;
            color: var(--text-color);
            background-color: #eceff1; /* Subtle neutral canvas around slide */
            font-size: 18px; /* Base font size for presentation */
        }

        .presentation-container {
            height: 100%;
            width: 100%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            gap: 0;
            background-color: transparent; /* Stage background; slide has its own */
        }

        .slide {
            display: none; /* Hidden by default */
            padding: 40px 60px;
            box-sizing: border-box;
            width: 100vw;
            height: 100vh;
            overflow: hidden; /* content wrapper will scroll */
            background: var(--slide-background);
            border-radius: 0; /* Edge-to-edge for full-screen crispness */
            box-shadow: none; /* Screen-filling: remove outer shadow */
            flex-shrink: 0;
            justify-content: flex-start; /* Align content to top */
            align-items: center; /* Center content horizontally */
            flex-direction: column; /* Stack content vertically */
            border: none;
        }

        .slide.active {
            display: flex; /* Show the active slide */
        }

        .slide-content-wrapper {
            max-width: 100%;
            width: 100%;
            height: 100%;
            padding: 10px 24px 90px 24px; /* leave space at bottom for footer overlay */
            box-sizing: border-box;
            overflow: auto; /* Scroll inside slide, not the page */
        }

        h1, h2, h3, h4, h5, h6 {
            color: var(--accent-color);
            line-height: 1.2;
            margin-top: 1.5em;
            margin-bottom: 0.8em;
        }

        h1 { font-size: 2.8em; text-align: center; margin-top: 0; padding-top: 20px; }
        h2 { font-size: 2.2em; }
        h3 { font-size: 1.8em; }
        p, li { font-size: 1em; }

        /* Machine-like hero styling for intro slide */
        .slide.machine-hero {
            background: 
                repeating-linear-gradient(
                    0deg,
                    rgba(0,0,0,0.04) 0px,
                    rgba(0,0,0,0.04) 1px,
                    transparent 1px,
                    transparent 20px
                ),
                repeating-linear-gradient(
                    90deg,
                    rgba(0,0,0,0.04) 0px,
                    rgba(0,0,0,0.04) 1px,
                    transparent 1px,
                    transparent 20px
                ),
                var(--slide-background);
            border: 1px solid #c9c9c9;
        }
        .slide.machine-hero h1 {
            font-weight: 800;
            letter-spacing: 0.01em;
            text-transform: uppercase;
            margin-bottom: 0.2em;
        }
        .slide.machine-hero .subtitle-sys {
            text-align: center;
            margin-top: 0;
            margin-bottom: 18px;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
            font-size: 0.95em;
            color: #555;
            letter-spacing: 0.08em;
            text-transform: uppercase;
        }
        .slide.machine-hero .json-block {
            background-color: #f2f4f5;
            border-left-color: #111;
            color: #333;
        }

        ul {
            list-style-type: disc;
            margin-left: 20px;
            margin-bottom: 1em;
        }

        ol {
            list-style-type: decimal;
            margin-left: 20px;
            margin-bottom: 1em;
        }

        li {
            margin-bottom: 0.5em;
        }

        a {
            color: var(--accent-color);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .json-block {
            background-color: #eee;
            border-left: 5px solid var(--accent-color);
            padding: 15px 20px;
            margin: 20px 0;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
            white-space: pre-wrap;
            word-break: break-all;
            font-size: 0.8em; /* Smaller for JSON blocks */
            color: #555;
            border-radius: 4px;
            align-self: flex-start; /* Align json block to left for intro */
        }
        .json-block pre {
            margin: 0;
        }

        .objectives-list {
            list-style-type: 'üëâ '; /* Custom bullet point */
            padding-left: 25px;
        }

        .notes {
            font-style: italic;
            color: #666;
            margin-top: 20px;
            padding: 15px;
            background-color: var(--highlight-color);
            border-left: 4px solid var(--border-color);
            border-radius: 4px;
            font-size: 0.85em;
        }

        .image-placeholder-container {
            margin: 30px 0;
            text-align: center;
        }

        .image-placeholder {
            max-width: 100%;
            max-height: 70vh; /* Use more screen while preventing overflow */
            height: auto;
            border: 1px dashed var(--border-color);
            border-radius: 4px;
            display: block;
            margin: 0 auto 10px auto;
            object-fit: contain; /* Ensures image fits without cropping */
        }

        /* Carousel mode for containers that hold multiple images */
        .image-placeholder-container.is-carousel { position: relative; }
        .image-placeholder-container.is-carousel img.image-placeholder { display: none; }
        .image-placeholder-container.is-carousel img.image-placeholder.selected { display: block; }
        .image-placeholder-container .carousel-nav {
            position: absolute;
            top: 50%;
            transform: translateY(-50%);
            width: 32px;
            height: 32px;
            border-radius: 50%;
            border: 1px solid var(--border-color);
            background: rgba(255,255,255,0.9);
            box-shadow: 0 2px 6px rgba(0,0,0,0.08);
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            color: var(--accent-color);
            font-size: 18px;
            line-height: 1;
            user-select: none;
        }
        .image-placeholder-container .carousel-nav.prev { left: 6px; }
        .image-placeholder-container .carousel-nav.next { right: 6px; }

        .alt-text, .visual-description {
            font-size: 0.8em;
            color: #777;
            margin-top: 5px;
            text-align: left;
        }

        .image-url-tip {
            font-size: 0.75em;
            color: #999;
            margin-top: 10px;
            background-color: #f5f5f5;
            padding: 8px;
            border-radius: 4px;
            display: inline-block;
            text-align: left;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.9em; /* Slightly smaller for tables */
        }

        th, td {
            border: 1px solid var(--border-color);
            padding: 12px 15px;
            text-align: left;
        }

        th {
            background-color: #f0f0f0;
            font-weight: bold;
        }

        .ritual-header { background-color: var(--ritual-color-bg); }
        .system-header { background-color: var(--system-color-bg); }

        .ritual-column { background-color: var(--ritual-color-bg); }
        .system-column { background-color: var(--system-color-bg); }

        .ritual-text { color: var(--ritual-color-text); font-weight: bold; }
        .system-text { color: var(--system-color-text); font-weight: bold; }

        sup {
            font-size: 0.7em;
            vertical-align: super;
            line-height: 0;
            position: relative;
            top: -0.5em;
            margin-left: 2px;
        }

        sup a {
            color: #555;
            text-decoration: none;
        }

        sup a:hover {
            text-decoration: underline;
        }

        .bibliography ol {
            list-style-type: decimal;
            margin-left: 20px;
        }
        .bibliography li {
            font-size: 0.85em;
            margin-bottom: 0.7em;
        }
        .bibliography li a {
            color: #007bff;
        }

        .checklist-item {
            display: flex;
            align-items: flex-start;
            margin-bottom: 0.8em;
        }
        .checklist-item::before {
            content: ''; /* No default bullet */
        }
        .checklist-item span {
            flex: 1;
            display: flex; /* For inline icon and text alignment */
            align-items: center;
        }

        /* Specific icon styling for checklist items */
        .icon {
            display: inline-block;
            width: 1.2em; /* Slightly larger for visibility */
            height: 1.2em;
            margin-right: 8px;
            vertical-align: middle;
            background-size: contain;
            background-repeat: no-repeat;
            background-position: center;
            flex-shrink: 0; /* Prevent icon from shrinking */
        }

        .icon-clipboard { background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2"></path><rect x="8" y="2" width="8" height="4" rx="1" ry="1"></rect></svg>'); }
        .icon-save { background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M19 21H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h11l5 5v11a2 2 0 0 1-2 2z"></path><polyline points="17 21 17 13 7 13 7 21"></polyline><polyline points="7 3 7 8 15 8"></polyline></svg>'); }
        .icon-question { background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><path d="M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"></path><line x1="12" y1="17" x2="12.01" y2="17"></line></svg>'); }
        /* A simple venn diagram icon */
        .icon-venn { background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="10" cy="12" r="8"></circle><circle cx="14" cy="12" r="8"></circle></svg>'); }

        .check-icon {
            color: #28a745; /* Bootstrap green */
            font-weight: bold;
            margin-right: 5px;
        }

        .cross-icon {
            color: #dc3545; /* Bootstrap red */
            font-weight: bold;
            margin-right: 5px;
        }

        /* Benefits & Risks table specific styling */
        .benefits-risks td:nth-child(2) { /* Ritual column */
            background-color: var(--ritual-color-bg);
        }
        .benefits-risks td:nth-child(3) { /* System column */
            background-color: var(--system-color-bg);
        }

        .venn-diagram-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 30px 0;
        }
        .venn-diagram {
            position: relative;
            width: 300px; /* Adjust size as needed */
            height: 180px;
            margin-top: 20px;
        }
        .venn-diagram .circle {
            position: absolute;
            width: 180px;
            height: 180px;
            border-radius: 50%;
            border: 2px solid var(--accent-color);
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 0.9em;
            color: var(--text-color);
            background-color: rgba(255, 255, 255, 0.7); /* Slightly transparent */
        }
        .venn-diagram .circle.ritual {
            left: 0;
            background-color: rgba(255, 240, 220, 0.4); /* ritual-color-bg with transparency */
            border-color: var(--ritual-color-text);
        }
        .venn-diagram .circle.system {
            right: 0;
            background-color: rgba(220, 240, 255, 0.4); /* system-color-bg with transparency */
            border-color: var(--system-color-text);
        }
        /* Overlap text positioning */
        .venn-diagram .overlap-text {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            text-align: center;
            width: 150px; /* Width for text */
            font-size: 0.8em;
            font-weight: bold;
            color: var(--accent-color);
            z-index: 10;
        }
        /* Adjust circles to create visual overlap */
        .venn-diagram .circle.ritual { left: 0; transform: translateX(25%); }
        .venn-diagram .circle.system { right: 0; transform: translateX(-25%); }

        .studio-exercise-prompt {
            background-color: #f0f8ff; /* Light blue */
            border: 1px dashed #a0d0ed;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            text-align: center;
            font-size: 1.1em;
            font-weight: bold;
        }

        .studio-exercise-visual {
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            margin-top: 20px;
        }
        .studio-exercise-visual .prompt-box {
            border: 1px solid var(--border-color);
            padding: 15px;
            margin: 10px;
            width: 45%;
            min-width: unset; /* Remove min-width for flexible scaling */
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
            background-color: #fff;
            border-radius: 5px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            font-size: 0.9em; /* Adjust for better fit on slides */
        }
        .studio-exercise-visual .prompt-box h4 {
            margin-top: 0;
            margin-bottom: 10px;
            color: #555;
            text-align: center;
        }
        .studio-exercise-visual .prompt-box p {
            font-style: italic;
            font-size: 1em;
            text-align: center;
        }
        .studio-exercise-visual .arrow {
            font-size: 2em;
            color: var(--accent-color);
            margin: 0 10px;
            white-space: nowrap; /* Prevent arrow from wrapping */
        }
        @media (max-width: 768px) {
            .studio-exercise-visual {
                flex-direction: column;
            }
            .studio-exercise-visual .prompt-box {
                width: 90%;
            }
            .studio-exercise-visual .arrow {
                margin: 20px 0;
                transform: rotate(90deg);
            }
        }

        .slide-footer {
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            padding: 10px 20px;
            font-size: 0.9em;
            color: #444;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 10px;
            border-top: 1px solid var(--border-color);
            background-color: rgba(250, 250, 250, 0.9);
            backdrop-filter: saturate(1.2) blur(4px);
            box-sizing: border-box;
            z-index: 100;
        }

        /* Notes visibility: hidden by default; toggle with body.show-notes */
        .notes { display: none; }
        body.show-notes .notes { display: block; }

        /* Hide instructional tip paragraphs about replacing image src */
        .image-url-tip { display: none !important; }

        /* Floating controls panel for image URL injection and notes toggle */
        .controls-panel {
            position: fixed;
            left: 20px;
            bottom: 60px; /* above footer */
            display: flex;
            align-items: center;
            gap: 8px;
            background: rgba(255,255,255,0.95);
            border: 1px solid var(--border-color);
            border-radius: 10px;
            padding: 8px 10px;
            box-shadow: 0 4px 16px rgba(0,0,0,0.08);
            z-index: 120;
        }
        .controls-panel input[type="url"] {
            width: 340px;
            max-width: 38vw;
            padding: 6px 8px;
            border: 1px solid var(--border-color);
            border-radius: 6px;
            font-size: 0.95em;
        }
        .controls-panel .mini-btn {
            appearance: none;
            border: 1px solid var(--border-color);
            background: white;
            color: var(--accent-color);
            border-radius: 6px;
            padding: 6px 10px;
            font-size: 0.9em;
            cursor: pointer;
        }
        .controls-panel .divider { width: 1px; height: 22px; background: var(--border-color); margin: 0 2px; }
        .controls-panel label { font-size: 0.9em; color: #666; display: inline-flex; align-items: center; gap: 6px; }

        /* Visual cue for selected image target */
        .image-placeholder { transition: box-shadow 0.15s ease, outline-color 0.15s ease; }
        .image-placeholder.selected {
            outline: 3px solid #90caf9;
            box-shadow: 0 0 0 4px rgba(144,202,249,0.25);
        }

        .nav-btn {
            appearance: none;
            border: 1px solid var(--border-color);
            background: white;
            color: var(--accent-color);
            border-radius: 6px;
            padding: 6px 12px;
            font-size: 0.95em;
            cursor: pointer;
            transition: background 0.15s ease, transform 0.05s ease;
        }
        .nav-btn:hover { background: #f3f3f3; }
        .nav-btn:active { transform: translateY(1px); }

        .footer-center {
            display: flex;
            align-items: center;
            gap: 12px;
            color: #666;
        }
        .footer-center .hint { color: #999; font-size: 0.85em; }

        .progress-bar {
            flex: 1 1 auto;
            height: 6px;
            background: #e9ecef;
            border-radius: 999px;
            overflow: hidden;
            margin-left: 10px;
        }
        .progress-bar .progress {
            height: 100%;
            width: 0%;
            background: linear-gradient(90deg, var(--accent-color), #666);
            border-radius: 999px;
            transition: width 200ms ease-out;
        }

        /* Click-to-navigate hint zones (no visible UI) */
        .nav-zone {
            position: fixed;
            top: 0; bottom: 0;
            width: 50vw;
            z-index: 50;
        }
        .nav-zone.left { left: 0; }
        .nav-zone.right { right: 0; }

        /* Print/PDF styles: stack slides, remove shadows, white background */
        @media print {
            html, body { overflow: visible; background: white; font-size: 12pt; }
            .presentation-container { align-items: stretch; }
            .slide {
                display: block !important;
                width: 100% !important;
                aspect-ratio: auto;
                max-height: none;
                box-shadow: none;
                border: none;
                page-break-inside: avoid;
                margin: 0 0 12mm 0;
            }
            .slide-footer, .nav-zone { display: none !important; }
        }
    </style>
</head>
<body>
    <div class="presentation-container">

        <!-- Slide 1: Introduction -->
        <div class="slide machine-hero" id="intro">
            <div class="slide-content-wrapper">
                <div class="json-block">
                    <pre><code>{
"course_session": "S6",
"title": "The Medium as Operator",
"date": "Thu 09/04",
"length_min": 75,
"slides_planned": 15,
"accent_color": "#111111",
"objectives": [
"Compare Carey vs Kittler",
"Define operative ekphrasis",
"Apply theory to AI text-image",
"Practice prompt rewriting"
]
}</code></pre>
                </div>
                <h1>The Medium as Operator</h1>
                <p class="subtitle-sys">Ritual ‚áÑ System ‚Ä¢ Protocols ‚Ä¢ Procedures</p>

                <p>‚Ä¢ Media don't just transmit messages - they script social life.</p>
                <p>‚Ä¢ What does a medium make us do?</p>
                <p>‚Ä¢ From church mass to circuits: media shape behavior beyond content.
                    <div class="image-placeholder-container">
                        <img src="https://via.placeholder.com/600x250?text=Cathedral+vs+Signal+Chain" alt="Left image shows people gathered in a cathedral (ritual communication). Right image shows a linear communication circuit with sender, channel, receiver (technical system)." class="image-placeholder">
                        <p class="visual-description"><strong>Visual:</strong> Side-by-side images - left: a congregation in a cathedral; right: a technical signal chain diagram.</p>
                        <p class="alt-text"><strong>ALT TEXT:</strong> Left image shows people gathered in a cathedral (ritual communication). Right image shows a linear communication circuit with sender, channel, receiver (technical system).</p>
                        <p class="image-url-tip"><em>User can replace 'src' above with actual image URL corresponding to the description. Example Left: <a href="https://unsplash.com/photos/a-crowd-of-people-standing-in-a-large-church-Y683-mF19t4" target="_blank">unsplash.com/photos/Y683-mF19t4</a>. Example Right: a conceptual signal chain diagram.</em></p>
                    </div>
                </p>
                <div class="notes">
                    <p><strong>Notes:</strong> This session explores how media act not only as carriers of content, but as forces that shape our actions and social reality. We pose a provocative question: "What does a medium make us do?" One side of the image (a cathedral congregation) evokes James Carey's idea of communication as a ritual ‚Äì a communal act that binds people together in shared meaning. The other side (a signal chain diagram) evokes Friedrich Kittler's view of media as technical systems ‚Äì machines and circuits that determine how information flows. This juxtaposition introduces our core claim: <span class="ritual-text">Media shape social life</span> ‚Äì either through cultural rituals or through technical operations ‚Äì rather than being neutral conduits. The stage is set to examine whether media function more like <span class="ritual-text">ceremonies</span> or <span class="system-text">machines</span>, and what that means for AI text-image generation.</p>
                </div>
            </div>
        </div>

        <!-- Slide 2: Today's Map & Objectives -->
        <div class="slide" id="today-map-objectives">
            <div class="slide-content-wrapper">
                <h2>Today's Map & Objectives</h2>
                <ul>
                    <li><strong>Ritual vs System:</strong> Compare Carey's and Kittler's views.</li>
                    <li><strong>Operative Ekphrasis:</strong> Define words <span class="system-text">doing images</span> (vs describing).</li>
                    <li><strong>Theory ‚Üí AI:</strong> Apply ritual/system models to text-image pipelines.</li>
                    <li><strong>Prompt Practice:</strong> Rewrite prompts with ritual vs technical focus.</li>
                    <li><strong>Flow:</strong> Compare ‚Üí Apply ‚Üí Practice ‚Üí Discuss.
                        <div class="image-placeholder-container">
                            <img src="https://via.placeholder.com/600x150?text=Roadmap+Diagram" alt="A linear roadmap diagram with four milestones labeled 'Compare', 'Define', 'Apply', 'Practice', leading to 'Discuss'." class="image-placeholder">
                            <p class="visual-description"><strong>Visual:</strong> A simple roadmap diagram with four milestones labeled "Compare,‚Äù ‚ÄúDefine,‚Äù ‚ÄúApply," "Practice," leading to "Discuss.‚Äù</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> A linear roadmap diagram showing the session flow: starting with Compare (Carey vs Kittler), then Define (operative ekphrasis), then Apply (to AI prompts), then Practice (prompt writing), and finally Discussion.</p>
                            <p class="image-url-tip"><em>User can replace 'src' above with actual image URL representing this description (e.g., a simple infographic of a flow from left to right).</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> Today's session is structured to build from theory to practice. First, we'll <span class="ritual-text">compare</span> two perspectives on media: Carey's cultural ritual view versus Kittler's materialist system view. Next, we'll <span class="system-text">define</span> a key concept ‚Äì <span class="system-text">operative ekphrasis</span> ‚Äì which connects those theories to how AI generates images from text. Then we'll <span class="ritual-text">apply</span> these ideas to analyze the text-to-image pipeline, seeing where social "ritual" elements and technical ‚Äúsystem" elements come into play. Finally, we'll <span class="system-text">practice</span> by rewriting an image prompt in two styles (ritual vs system) and then <span class="ritual-text">discuss</span> our insights. By the end, you should be able to (1) distinguish the ritual view from the deterministic view of media, (2) explain what operative ekphrasis means, (3) diagnose how AI prompts act as procedures, and (4) tweak your own prompts using both cultural cues and technical parameters. The flowchart visual shows this map: we'll <span class="ritual-text">Compare</span> theories, <span class="system-text">Define</span> new terms, <span class="ritual-text">Apply</span> them to AI, <span class="system-text">Practice</span> prompt writing, and conclude with a <span class="ritual-text">Discussion</span>.</p>
                </div>
            </div>
        </div>

        <!-- Slide 3: Carey's Ritual View -->
        <div class="slide" id="carey-ritual-view">
            <div class="slide-content-wrapper">
                <h2>Carey's Ritual View of Communication</h2>
                <ul>
                    <li>Communication as <span class="ritual-text">ritual</span> (a shared cultural ceremony)<sup id="ref-1-back"><a href="#ref-1">1</a></sup></li>
                    <li>Emphasis on <span class="ritual-text">participation</span>, <span class="ritual-text">fellowship</span>, <span class="ritual-text">common belief</span><sup id="ref-2-back"><a href="#ref-2">2</a></sup></li>
                    <li>Not about sending info, but affirming a <span class="ritual-text">worldview</span><sup id="ref-3-back"><a href="#ref-3">3</a></sup></li>
                    <li>Example: Reading news = attending daily mass (no new info, but shared meaning)<sup id="ref-3-back"><a href="#ref-3">3</a></sup>
                        <div class="image-placeholder-container">
                            <img src="https://via.placeholder.com/600x300?text=Reading+News+as+Ritual" alt="Sketch of a group of people reading newspapers in unison, superimposed on faint church imagery ‚Äì highlighting news reading as a ritual act." class="image-placeholder">
                            <p class="visual-description"><strong>Visual:</strong> Illustration of people reading newspapers together in a caf√©, with an aura of a church gathering in the background.</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> Sketch of a group of people reading newspapers in unison, superimposed on faint church imagery ‚Äì highlighting news reading as a ritual act.</p>
                            <p class="image-url-tip"><em>User can replace 'src' above with actual image URL representing this description.</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> James W. Carey introduced a <span class="ritual-text">ritual view of communication</span><sup id="ref-1-back"><a href="#ref-1">1</a></sup>. In this view, communication is like attending a ceremony or mass ‚Äì it's about <span class="ritual-text">participation</span> and <span class="ritual-text">shared beliefs</span>, not just sending information. Carey defines the ritual view with words like <span class="ritual-text">sharing</span>, <span class="ritual-text">association</span>, <span class="ritual-text">fellowship</span>, <span class="ritual-text">communion</span><sup id="ref-2-back"><a href="#ref-2">2</a></sup>, highlighting how communication acts (like reading a daily newspaper) bring people together in a shared symbolic world. Importantly, the ritual view contrasts with the typical "transmission" view. Instead of focusing on delivering new facts or messages, the ritual view sees media use as repeating and confirming what a community holds in common<sup id="ref-3-back"><a href="#ref-3">3</a></sup>. For example, Carey famously likens reading the morning news to attending a religious mass: nothing dramatically new is learned, but a particular view of the world is portrayed and confirmed each day<sup id="ref-3-back"><a href="#ref-3">3</a></sup>. The newspaper ritual doesn't primarily transmit fresh data; it reassures readers of their social reality and identity. Thus, media (in Carey's sense) serve to <span class="ritual-text">maintain society in time</span> ‚Äì continually renewing a sense of community and shared meaning.</p>
                </div>
            </div>
        </div>

        <!-- Slide 4: Kittler's Materialist Media Theory -->
        <div class="slide" id="kittler-materialist-theory">
            <div class="slide-content-wrapper">
                <h2>Kittler's Materialist Media Theory</h2>
                <ul>
                    <li>"<span class="system-text">Media determine our situation</span>"<sup id="ref-4-back"><a href="#ref-4">4</a></sup> - technology shapes discourse.</li>
                    <li><span class="system-text">Devices</span> (gramophone, film, typewriter) store & limit what can be said<sup id="ref-5-back"><a href="#ref-5">5</a></sup>.</li>
                    <li>Humans adapt to machines: "The machine does not adapt to us"<sup id="ref-6-back"><a href="#ref-6">6</a></sup>.</li>
                    <li>Media follow their own logic (beyond human intent)<sup id="ref-7-back"><a href="#ref-7">7</a></sup>.
                        <div class="image-placeholder-container">
                            <img src="https://via.placeholder.com/600x300?text=Layered+Tech+Stack" alt="A schematic stack of media technologies (record player, film reel, typewriter, computer) with arrows indicating how each medium imposes its own rules on communication." class="image-placeholder">
                            <p class="visual-description"><strong>Visual:</strong> Diagram of a layered tech stack (phonograph, camera, computer) with arrows showing influence on language and culture.</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> A schematic stack of media technologies (record player, film reel, typewriter, computer) with arrows indicating how each medium imposes its own rules on communication.</p>
                            <p class="image-url-tip"><em>User can replace 'src' above with actual image URL representing this description.</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> Friedrich A. Kittler offers a <span class="system-text">materialist, deterministic view</span> of media. He famously opened *Gramophone, Film, Typewriter* with the bold statement: "<span class="system-text">Media determine our situation</span>."<sup id="ref-4-back"><a href="#ref-4">4</a></sup> In Kittler's perspective, the technical apparatus of media ‚Äì the machines and formats like phonographs, cinema, typewriters, later computers ‚Äì fundamentally <span class="system-text">dictate how information is recorded and communicated</span>. He notes that "what remains of people is what media can store and communicate"<sup id="ref-4-back"><a href="#ref-4">4</a></sup>, suggesting that our cultural memory and even identity are constrained by the storage and transmission capacities of our devices. Unlike human-centered views, Kittler emphasizes that <span class="system-text">humans must adapt to their machines, not vice-versa</span>. He stated, regarding the Internet, that it's more about humans becoming "a reflection of their technologies... we adapt to the machine. The machine does not adapt to us."<sup id="ref-6-back"><a href="#ref-6">6</a></sup> This means media technologies have an <span class="system-text">autonomous influence</span> ‚Äì they have their own logic. For example, each medium (be it the typewriter or the computer) enforces certain formats and possibilities (and shuts out others) for discourse. Kittler even countered McLuhan's idea of media as mere extensions of man, saying instead that <span class="system-text">media are not human prostheses</span>; they follow a trajectory of technical escalation beyond human control<sup id="ref-7-back"><a href="#ref-7">7</a></sup>. In short, Kittler's view is <span class="system-text">deterministic</span>: the properties of media hardware and code largely determine how we communicate and what can be expressed in a given era.</p>
                </div>
            </div>
        </div>

        <!-- Slide 5: Ritual vs. System: Comparing Carey & Kittler -->
        <div class="slide" id="comparison-carey-kittler">
            <div class="slide-content-wrapper">
                <h2>Ritual vs. System: Comparing Carey & Kittler</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Aspect</th>
                            <th class="ritual-header">Ritual View<br>(Carey)</th>
                            <th class="system-header">Material View<br>(Kittler)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Unit of focus</td>
                            <td class="ritual-column">Communal acts & symbols (culture)</td>
                            <td class="system-column">Media devices & codes (tech)</td>
                        </tr>
                        <tr>
                            <td>Causality</td>
                            <td class="ritual-column">Social ritual shapes meaning (two-way)</td>
                            <td class="system-column">Technology drives discourse (deterministic)</td>
                        </tr>
                        <tr>
                            <td>Temporality</td>
                            <td class="ritual-column">Cyclical, time-binding (repeated ceremonies)</td>
                            <td class="system-column">Epochal, time-storing (media eras)</td>
                        </tr>
                        <tr>
                            <td>Agency</td>
                            <td class="ritual-column">Human participants (community agency)</td>
                            <td class="system-column">Machines/systems (technical agency)</td>
                        </tr>
                    </tbody>
                </table>
                <p> - Different focuses: one on cultural meaning, the other on technical mechanism.</p>
                <p> - Together, they reveal media as both a social and a technical script.</p>
                <div class="notes">
                    <p><strong>Visual:</strong> A split table highlighting differences: the left column in a warm color for "ritual/culture," the right in a cool color for "system/tech."</p>
                    <p><strong>ALT TEXT:</strong> Table comparing Carey vs Kittler - e.g., Carey focuses on community rituals and cyclic time, whereas Kittler focuses on devices, deterministic influence, and historical tech shifts.</p>
                    <p><strong>Notes:</strong> This comparison matrix summarizes how Carey and Kittler diverge in their approach to media. For Carey, the fundamental unit is a <span class="ritual-text">symbolic ritual</span> ‚Äì communication events embedded in culture (like ceremonies, shared narratives). For Kittler, the unit is the <span class="system-text">technical medium itself</span> ‚Äì the devices and formats (gramophone, film, typewriter, etc.) that store and transmit data. In terms of <span class="ritual-text">causality</span>, Carey's ritual view implies a more <span class="ritual-text">reciprocal relationship</span>: communication rituals evolve from and reinforce social needs and meanings (society shapes how media are used, and media rituals in turn sustain society). Kittler's view is more <span class="system-text">one-directional</span>: the capabilities of technology <span class="system-text">drive</span> changes in discourse and culture (e.g. the invention of recording devices fundamentally altered what can be communicated). On <span class="ritual-text">temporality</span>, Carey emphasizes <span class="ritual-text">cyclical time</span> - rituals are repeated over time to maintain continuity (daily, weekly traditions that bind a community across generations). Kittler emphasizes <span class="system-text">historical ruptures</span> ‚Äì new media technologies introduce distinct eras (e.g. the shift from oral to print to electronic media), with each era's communications defined by its machines' storage and speed. Finally, regarding <span class="ritual-text">agency</span>, Carey grants agency to <span class="ritual-text">people in community</span> - communicators actively creating shared meaning. Kittler, by contrast, almost personifies <span class="system-text">machines as agents</span> - technologies operate according to their own logic, with humans adapting around them. These two views can talk past each other (cultural context vs. hardware), but they can also be <span class="ritual-text">complementary</span>: taken together, they remind us that media are simultaneously cultural practices and technical infrastructures. Media both script how we belong together socially and script what is practically possible in communication.</p>
                </div>
            </div>
        </div>

        <!-- Slide 6: From Ekphrasis to Operative Ekphrasis -->
        <div class="slide" id="operative-ekphrasis">
            <div class="slide-content-wrapper">
                <h2>From Ekphrasis to Operative Ekphrasis</h2>
                <ul>
                    <li><strong>Classical ekphrasis:</strong> vivid verbal description of an artwork (words <em>about</em> images).</li>
                    <li><strong>Operative ekphrasis (Bajohr):</strong> text that <span class="system-text">produces an image via technical means</span><sup id="ref-8-back"><a href="#ref-8">8</a></sup>.</li>
                    <li>AI blurs text/image: language generates pictures directly (prompt as creative act)<sup id="ref-8-back"><a href="#ref-8">8</a></sup>.
                        <div class="image-placeholder-container">
                            <img src="https://via.placeholder.com/600x300?text=Poet+vs+AI+Prompt" alt="Left panel: a poet observes a Grecian urn and writes a descriptive poem (ekphrasis). Right panel: a user enters a text prompt into an AI, and an image emerges (operative ekphrasis)." class="image-placeholder">
                            <p class="visual-description"><strong>Visual:</strong> Two panels - left: a poet describing a vase; right: a computer console where text is turning into an image.</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> Left panel: a poet observes a Grecian urn and writes a descriptive poem (ekphrasis). Right panel: a user enters a text prompt into an AI, and an image emerges (operative ekphrasis).</p>
                            <p class="image-url-tip"><em>User can replace 'src' above with actual image URL representing this description (e.g., a side-by-side illustration of classical art description vs AI prompt).</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> The term <span class="ritual-text">ekphrasis</span> traditionally refers to a written description of a visual artwork. Think of a poem that so richly describes a painting or sculpture that the image comes alive in the reader's mind ‚Äì that's classical ekphrasis (words about an image). For example, Keats's poem describing a Grecian urn is ekphrastic: it uses language to represent a visual art piece. Now, media theorist Hannes Bajohr introduces the idea of <span class="system-text">operative ekphrasis</span> in the context of AI<sup id="ref-8-back"><a href="#ref-8">8</a></sup>. This is a new twist: instead of words passively describing an existing image, words are used to <span class="system-text">actively generate a new image</span>. In multimodal AI systems (like text-to-image generators), the line between text and image collapses ‚Äì you input a textual prompt, and a novel picture is produced<sup id="ref-8-back"><a href="#ref-8">8</a></sup>. So the text isn't just storytelling; it's <span class="system-text">operational</span>. Bajohr says "language here produces images"<sup id="ref-8-back"><a href="#ref-8">8</a></sup> ‚Äì the prompt performs like an instruction in a "performative constellation." In short, <span class="system-text">operative ekphrasis</span> is when text functions as an <span class="system-text">operator</span>: it directly causes the creation of visual content. This concept helps us see AI prompts as a kind of procedural poetry or code ‚Äì words that do something (conjure images) rather than just say something. We're moving from communication as representation to <span class="system-text">communication as action in a system</span>.</p>
                </div>
            </div>
        </div>

        <!-- Slide 7: Keats & Apollinaire: Bridges from Art to AI -->
        <div class="slide" id="keats-apollinaire">
            <div class="slide-content-wrapper">
                <h2>Keats & Apollinaire: Bridges from Art to AI</h2>
                <ul>
                    <li><strong>Keats's urn (1819):</strong> Ekphrastic poetry capturing a <span class="ritual-text">frozen moment</span> ‚Äì lovers "forever panting, forever young"<sup id="ref-9-back"><a href="#ref-9">9</a></sup>. Words invite reflection on an image.</li>
                    <li><strong>Apollinaire's calligrammes (1914):</strong> Poems arranged as visual art ‚Äì a "poem picture" that uses words like paint<sup id="ref-10-back"><a href="#ref-10">10</a></sup>.</li>
                    <li><strong>From description to operation:</strong> Keats describes art to evoke feeling; Apollinaire's words perform visually. Foreshadows prompts as word-images.
                        <div class="image-placeholder-container">
                            <img src="https://via.placeholder.com/600x300?text=Keats+Urn+vs+Apollinaire+Calligramme" alt="Left: Excerpt of Keats's 'Ode on a Grecian Urn,' with lines about lovers frozen in time. Right: Apollinaire's calligram poem where the text is arranged in the shape of the Eiffel Tower ‚Äì words literally forming an image." class="image-placeholder">
                            <p class="visual-description"><strong>Visual:</strong> Side-by-side: a page of Keats's "Ode on a Grecian Urn" with an urn sketch, and Apollinaire's calligram poem forming an image (e.g., a Eiffel Tower shape).</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> Left: Excerpt of Keats's "Ode on a Grecian Urn," with lines about lovers frozen in time. Right: Apollinaire's calligram poem where the text is arranged in the shape of the Eiffel Tower ‚Äì words literally forming an image.</p>
                            <p class="image-url-tip"><em>User can replace 'src' above with actual image URL representing this description (e.g., an illustration of Keats's poem next to an Apollinaire calligramme).</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> Historical examples in art and literature prefigure our modern prompts. John Keats's "Ode on a Grecian Urn" (1819) is a classic ekphrasis ‚Äì a poem that describes the scenes on an ancient urn. Keats dwells on the stillness of the urn's imagery: the lovers on the urn will never kiss, yet they remain "for ever warm and still to be enjoy'd, for ever panting, and for ever young"<sup id="ref-11-back"><a href="#ref-11">11</a></sup>. His words capture a <span class="ritual-text">frozen moment</span> in time and invite the reader to contemplate the eternal beauty and sadness of that unmoving image. This is language used to <span class="ritual-text">reflect on an image</span> (descriptive, interpretive). Jump to early 20th century: Guillaume Apollinaire created <span class="system-text">calligrammes</span> ‚Äì poems that are laid out on the page to form pictures. For example, he wrote a poem in the shape of the Eiffel Tower. In a sense, Apollinaire "painted with words." As one commentary notes, he made ‚Äúa 'written portrait', a 'poem picture'"<sup id="ref-10-back"><a href="#ref-10">10</a></sup>, breaking the conventions of poetry to make readers see something new. The text itself became visual art. These two are <span class="ritual-text">bridges</span>: Keats showed how richly words can describe an image; Apollinaire showed that words can be images. Together they anticipate the logic of AI prompting: we use words not just to talk about visuals, but to <span class="system-text">create visuals</span>. The lineage goes from describing art (Keats) ‚Üí words becoming art (Apollinaire) ‚Üí to today's prompts where typing a description actually <span class="system-text">materializes an image</span>. In other words, artistic and literary experiments have been paving the way for treating language as a creative instrument or apparatus, much like we do with text-to-image systems.</p>
                </div>
            </div>
        </div>

        <!-- Slide 8: Prompting Tips: ‚ÄúSay What You See‚Äù (Wild) -->
        <div class="slide" id="prompting-tips">
            <div class="slide-content-wrapper">
                <h2>Prompting Tips: ‚ÄúSay What You See‚Äù (Wild)</h2>
                <ul>
                    <li><strong>Be specific:</strong> Include medium, subject, context, and visual details<sup id="ref-12-back"><a href="#ref-12">12</a></sup></li>
                    <li>Name objects and attributes clearly (who, what, where, color, style).</li>
                    <li>Use short, comma-separated phrases (not long sentences) for clarity.</li>
                    <li>Include art style or era if relevant (e.g. oil painting, Baroque period).
                        <div class="image-placeholder-container">
                            <img src="https://via.placeholder.com/600x200?text=Prompt+Editing+Interface" alt="An example prompt box showing a vague prompt ('a library scene') versus a detailed prompt ('film photograph of an ancient library, dusty books, warm golden light, 35mm') - demonstrating the 'say what you see' approach." class="image-placeholder">
                            <p class="visual-description"><strong>Visual:</strong> A screenshot-style graphic of a prompt editing interface with examples of good vs. vague prompts (e.g., adding specifics like "photograph, dusty medieval library, warm light").</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> An example prompt box showing a vague prompt ("a library scene") versus a detailed prompt ("film photograph of an ancient library, dusty books, warm golden light, 35mm") - demonstrating the "say what you see" approach.</p>
                            <p class="image-url-tip"><em>User can replace 'src' above with actual image URL representing this description (e.g., a screenshot of a prompt input field).</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> When writing prompts for AI images, the advice is: "<span class="ritual-text">Say what you see</span>." This phrase comes from a Google Arts & Culture experiment by artist Jack Wild that coaches users in prompt writing. The key idea is to be as <span class="system-text">concrete and explicit as possible</span> about the visual elements. For example, instead of a vague prompt like "a beautiful scene," specify what is in the scene (subjects/objects), <span class="system-text">where and when</span> it is (context, setting, lighting), and <span class="system-text">how</span> it should look (medium or style)<sup id="ref-12-back"><a href="#ref-12">12</a></sup>. In practical terms, a strong prompt often mentions the <span class="system-text">medium</span> (e.g., photo, painting, 3D render), the <span class="system-text">subject</span> (e.g., an astronaut, a medieval library), plus descriptive <span class="system-text">attributes</span> and <span class="system-text">context</span> (e.g., dusty wooden shelves, warm light filtering through windows). It helps to list these as short phrases separated by commas, rather than a run-on sentence - image models interpret concise keywords better<sup id="ref-13-back"><a href="#ref-13">13</a></sup>. Also, include any <span class="system-text">style or era cues</span> if desired, such as "in the style of Rembrandt‚Äù or ‚ÄúVictorian-era illustration". Jack Wild's game even suggests noting textures or materials and art period<sup id="ref-12-back"><a href="#ref-12">12</a></sup> if relevant (for instance, ‚Äúmarble sculpture, Renaissance period"). By literally describing what you imagine ‚Äì essentially narrating the image's details - you guide the AI to meet the "visual threshold" of accuracy. In short, treat the prompt like you're <span class="system-text">directing an unseen artist</span>: spell out every important detail so the system knows exactly what to draw.</p>
                </div>
            </div>
        </div>

        <!-- Slide 9: Text-to-Image Pipeline (Mechanics) -->
        <div class="slide" id="text-to-image-pipeline">
            <div class="slide-content-wrapper">
                <h2>Text-to-Image Pipeline (Mechanics)</h2>
                <ul>
                    <li><strong>1. Prompt (user input):</strong> You write a textual prompt (shaped by your intent & culture).</li>
                    <li><strong>2. Text Encoder:</strong> The prompt is tokenized & converted to vectors (system formatting).</li>
                    <li><strong>3. Diffusion Model:</strong> The AI model processes those vectors to guide image generation.</li>
                    <li><strong>4. Sampler & Parameters:</strong> Algorithm iteratively refines an image (steps, noise seed, model settings).</li>
                    <li><strong>5. Output Image:</strong> An image is produced, then interpreted by humans (back to social context).
                        <div class="image-placeholder-container">
                            <img src="https://via.placeholder.com/600x150?text=AI+Pipeline+Flowchart" alt="Diagram showing the stages from text prompt to generated image: (1) user prompt, (2) text encoded to numeric vectors, (3) AI diffusion model generates latent image, (4) iterative sampling with a chosen seed and algorithm, (5) final output image." class="image-placeholder">
                            <p class="visual-description"><strong>Visual:</strong> Flowchart of the pipeline: box for "Prompt" ‚Üí arrow to "Tokenizer/Encoder" ‚Üí arrow to "Diffusion Model‚Äù ‚Üí arrow to "Sampler (steps/seed)" ‚Üí arrow to ‚ÄúGenerated Image."</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> Diagram showing the stages from text prompt to generated image: (1) user prompt, (2) text encoded to numeric vectors, (3) AI diffusion model generates latent image, (4) iterative sampling with a chosen seed and algorithm, (5) final output image.</p>
                            <p class="image-url-tip"><em>User can replace 'src' above with actual image URL representing this description (e.g., a flowchart graphic).</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> Let's break down how an AI text-to-image system works, noting where <span class="ritual-text">human ritual</span> and <span class="system-text">technical system</span> elements come into play. Step 1: <span class="ritual-text">Prompt creation</span>. A human user formulates a prompt in natural language. This step is influenced by the user's imagination, cultural references, and even community prompt norms (a <span class="ritual-text">ritual aspect</span> e.g., using popular styles or keywords that others have found effective). Step 2: <span class="system-text">Text encoding</span>. The prompt text is fed into the AI's language encoder (like CLIP). Here the system <span class="system-text">tokenizes the text</span> - i.e., breaks it into numeric codes or word embeddings. This is a purely <span class="system-text">technical process</span>; the user's rich language is reduced to vectors the model can handle (some nuance might be lost or forced into the model's pre-trained vocabulary ‚Äì a <span class="system-text">system constraint</span>). Step 3: <span class="system-text">Diffusion model generation</span>. The model (a neural network trained on image-text pairs) uses the encoded prompt to generate an image representation. In diffusion models, this often means starting from random noise and iteratively refining an image that matches the prompt's embedding. The model's learned data (its "training") heavily influences what it produces - this is the <span class="system-text">deterministic side</span>: the output is shaped by what the system knows from training. Step 4: <span class="system-text">Sampler and parameters</span>. The generation process depends on algorithmic settings: e.g., the number of diffusion steps, the specific sampler method, and a random seed value. These technical parameters act like the "knobs" a system operator can tweak (e.g., setting a seed makes the result reproducible, choosing a sampler changes the style of noise removal). A very "system" perspective is to treat these parameters as part of the prompt. Step 5: <span class="ritual-text">Output image</span>. Finally, the model outputs an image. Now we loop back to the human side: people will view and interpret that image, maybe share it, maybe tweak the prompt based on whether it fit the intended idea. This last step reintroduces the <span class="ritual-text">ritual/cultural context</span> - the image gains meaning only when humans see it and discuss it. In summary, throughout the pipeline, we see a dance between human intention (<span class="ritual-text">ritual, meaning-making</span>) and machine procedure (<span class="system-text">system, rules</span>): we craft the prompt creatively, the AI processes it mechanically, and we then incorporate the result back into our creative or social process.</p>
                </div>
            </div>
        </div>

        <!-- Slide 10: Case Study: Two Prompts, Two Approaches -->
        <div class="slide" id="case-study">
            <div class="slide-content-wrapper">
                <h2>Case Study: Two Prompts, Two Approaches</h2>
                <ul>
                    <li><strong>Prompt A (<span class="ritual-text">Ritual style</span>):</strong> ‚ÄúTwilight village festival, families share stories around a bonfire, warm nostalgic glow." - Narrative, evocative scene, minimal tech terms.</li>
                    <li><strong>Prompt B (<span class="system-text">System style</span>):</strong> ‚ÄúPhoto, 8K detail, night scene of people around bonfire, high contrast lighting, StableDiffusion1.5, Euler sampler 50 steps, seed=42." ‚Äì Explicit format, parameters, and style cues.</li>
                    <li><strong>Outcome:</strong> A ‚Äì open-ended, interprets cultural vibe; B ‚Äì tightly controlled, reproducible specifics.
                        <div class="image-placeholder-container">
                            <img src="https://via.placeholder.com/600x300?text=Prompt+A+vs+Prompt+B+Images" alt="A) a dreamy village bonfire scene (softer, interpretive), B) a more sharply defined, precise night photo of a bonfire gathering." class="image-placeholder">
                            <p class="visual-description"><strong>Visual:</strong> Two AI-generated images side by side: A) a dreamy village bonfire scene (softer, interpretive), B) a more sharply defined, precise night photo of a bonfire gathering.</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> Left: Image generated from a narrative prompt (village festival at twilight) ‚Äì it has a warm, storybook quality. Right: Image from a technical prompt (photo with specified settings) ‚Äì it looks like a crisp, high-definition night photograph, precisely rendered.</p>
                            <p class="image-url-tip"><em>User can replace 'src' above with actual image URL representing this description (e.g., two distinct AI-generated images of a bonfire scene based on the prompts).</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> Consider these two prompts about essentially the same subject (people around a bonfire at dusk) but framed very differently:</p>
                    <ul>
                        <li><strong>Prompt A</strong> is written in a <span class="ritual-text">ritual/descriptive mode</span>. It says: ‚ÄúTwilight village festival, families share stories around a bonfire, warm nostalgic glow." This reads almost like a line from a story. It emphasizes the atmosphere and social context (families, festival, nostalgia). It doesn't specify any camera or model details. The prompt trusts the AI to fill in details based on the general scene described. The result from Prompt A might be an image that captures the mood ‚Äì perhaps somewhat impressionistic ‚Äì but each time you run it, you could get a different interpretation (one time more people, another time more focus on fire, etc.). It leverages the AI's training on cultural scenes.</li>
                        <li><strong>Prompt B</strong> is written in a <span class="system-text">system/technical mode</span>. For example: ‚ÄúPhoto, 8K detail, night scene of people around bonfire, high contrast lighting, Stable Diffusion 1.5, Euler a, 50 steps, seed 42." This prompt front-loads technical instructions: it explicitly says we want a photograph-like image, with ultra high detail, specifies the lighting style, and even includes the exact AI model and sampler method, number of steps, and a random seed for reproducibility. This is like talking directly to the machine in its own terms. When these prompts are executed:</li>
                    </ul>
                    <ul>
                        <li><strong>Prompt A's output</strong> might emphasize the feeling of a communal bonfire night - it could be a bit unpredictable or artistic, guided by the model's general understanding of "village festival." It's great for creativity but if you wanted a very specific outcome, it might vary.</li>
                        <li><strong>Prompt B's output</strong> would likely be more consistent: because we set a seed, multiple runs produce the same image. The style ("photo, high contrast 8K‚Äù) will be very literally realized by the AI. The image will likely be sharp and defined exactly as instructed. In essence, Prompt A is like a <span class="ritual-text">ritual invocation</span> ‚Äì painting a scene to evoke meaning ‚Äì whereas Prompt B is like <span class="system-text">programming an image</span>, giving the machine exact directions. Each has its use: A might yield more surprise and aesthetic nuance, B gives more control and repeatability.</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 11: Studio Exercise: Rewrite a Prompt (5 min) -->
        <div class="slide" id="studio-exercise">
            <div class="slide-content-wrapper">
                <h2>Studio Exercise: Rewrite a Prompt (5 min)</h2>
                <ul>
                    <li><strong>Given (descriptive):</strong> "A couple under spring trees, reaching for a kiss, frozen in time."</li>
                    <li><strong>Task:</strong> Add medium, style, and parameters to make this an operative prompt.</li>
                    <li>Work individually for 5 minutes. Think: how would Carey vs. Kittler tweak this?</li>
                    <li><strong>Goal:</strong> See how adding ritual context or technical specs changes the outcome.
                        <div class="image-placeholder-container">
                            <div class="studio-exercise-visual">
                                <div class="prompt-box">
                                    <h4>Original Prompt</h4>
                                    <p>"A couple under spring trees, reaching for a kiss, frozen in time."</p>
                                </div>
                                <span class="arrow">‚û°Ô∏è</span>
                                <div class="prompt-box">
                                    <h4>Enhanced Operative Prompt</h4>
                                    <p>"Oil painting, golden-hour light, couple under trees about to kiss, highly detailed"</p>
                                </div>
                            </div>
                            <p class="visual-description"><strong>Visual:</strong> The given prompt text on a notepad, with arrows pointing to an enhanced prompt that includes camera and style annotations.</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> Text of the original prompt ("couple under spring trees about to kiss...") on the left, and on the right, an edited version with additions like "oil painting, golden hour light, highly detailed" ‚Äì illustrating the transformation into an operative prompt.</p>
                            <p class="image-url-tip"><em>This visual is conceptual and implemented directly in HTML/CSS.</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> Now it's your turn to apply these concepts. We have a starting prompt: "A couple under spring trees, reaching for a kiss, frozen in time." This is a <span class="ritual-text">descriptive/ekphrastic prompt</span> ‚Äì you can imagine it as a line from a poem or story (in fact, it's inspired by Keats's urn lovers). By itself, it sets a scene and mood, but it doesn't give the AI any guidance on how to render it. Your task is to <span class="system-text">rewrite this prompt in an operative style</span>, adding the kind of details that an AI system would need to generate a specific image. Think about what we learned:</p>
                    <ul>
                        <li>Include a medium or style: e.g., "oil painting‚Äù, ‚Äúphotograph‚Äù, ‚Äúwatercolor illustration‚Äù, etc.</li>
                        <li>Include contextual and visual details: e.g., ‚Äúat golden hour with petals falling‚Äù, or ‚Äúsoft diffused light, vintage style" ‚Äì whatever fits the effect you want.</li>
                        <li>You can also include technical parameters or adjectives like ‚Äúhigh resolution‚Äù, ‚Äú35mm lens‚Äù, or even a <span class="system-text">seed number</span> or specific model if you know it. Essentially, transform the prompt from a purely narrative description into a set of <span class="system-text">instructions for image generation</span>. You have 5 minutes to do this. Be creative! You might produce something like: ‚ÄúCinematic oil painting, golden-hour light through blossoms, a young couple under trees about to kiss, highly detailed, 4K resolution.‚Äù There's no single correct answer; the goal is to practice toggling between a ritual, imaginative mindset and a system, procedural mindset. After 5 minutes, we'll discuss a few examples ‚Äì what changed, and how those changes reflect the ritual vs system approaches.</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 12: Benefits & Risks: Ritual vs. System -->
        <div class="slide" id="benefits-risks">
            <div class="slide-content-wrapper">
                <h2>Benefits & Risks: Ritual vs. System</h2>
                <div class="image-placeholder-container">
                    <img src="https://via.placeholder.com/600x300?text=Ritual+vs+System+Balance" alt="A comparison chart listing advantages (+) and drawbacks (-) for both approaches: for Ritual (e.g., meaningful but potentially biased, unique but unreproducible) and for System (e.g., precise but maybe uninspired, reproducible but gated by expertise)." class="image-placeholder">
                    <p class="visual-description"><strong>Visual:</strong> A balanced scale diagram - one side labeled "Ritual (Culture)" and the other "System (Tech)" ‚Äì with pros and cons listed on each side.</p>
                    <p class="alt-text"><strong>ALT TEXT:</strong> A comparison chart listing advantages (+) and drawbacks (-) for both approaches: for Ritual (e.g., meaningful but potentially biased, unique but unreproducible) and for System (e.g., precise but maybe uninspired, reproducible but gated by expertise).</p>
                    <p class="image-url-tip"><em>User can replace 'src' above with actual image URL representing this description (e.g., a diagram resembling a balanced scale).</em></p>
                </div>
                <table class="benefits-risks">
                    <thead>
                        <tr>
                            <th>Aspect</th>
                            <th class="ritual-header">Ritual Approach<br>(media as cultural ritual)</th>
                            <th class="system-header">System Approach<br>(media as technical system)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Representation</td>
                            <td class="ritual-column"><span class="check-icon">‚úì</span> Culturally rich, meaningful images; <span class="cross-icon">‚úó</span> Can reinforce existing biases or myths.</td>
                            <td class="system-column"><span class="check-icon">‚úì</span> Precise, controllable outputs; <span class="cross-icon">‚úó</span> May lack context or produce generic results.</td>
                        </tr>
                        <tr>
                            <td>Reproducibility</td>
                            <td class="ritual-column"><span class="check-icon">‚úì</span> Inspires unique, one-off creations (creative variation); <span class="cross-icon">‚úó</span> Hard to exactly reproduce or verify.</td>
                            <td class="system-column"><span class="check-icon">‚úì</span> Consistent outputs with same parameters (version control); <span class="cross-icon">‚úó</span> Can become formulaic, less serendipitous.</td>
                        </tr>
                        <tr>
                            <td>Power</td>
                            <td class="ritual-column"><span class="check-icon">‚úì</span> Accessible - anyone can use familiar language (empowers users as storytellers); <span class="cross-icon">‚úó</span> Hidden tech influence (obscures the system's control, user might be unaware of model biases).</td>
                            <td class="system-column"><span class="check-icon">‚úì</span> Transparent control - expert users can master tool settings (empowers technical mastery); <span class="cross-icon">‚úó</span> Power concentrates to those with knowledge or access (tech gatekeepers, complexity barrier).</td>
                        </tr>
                    </tbody>
                </table>
                <p> - <strong>Provenance tip:</strong> System-style prompting enables tracking (e.g., recording seed, model version) for accountability; ritual style emphasizes storytelling but may hide the "how" behind results.</p>
                <div class="notes">
                    <p><strong>Notes:</strong> Both the ritual and system approaches to media (and to prompt-writing) come with <span class="system-text">trade-offs</span>. This table outlines some benefits (‚úî) and risks (x) of each:</p>
                    <ul>
                        <li><strong>Representation:</strong> The <span class="ritual-text">ritual approach</span> can produce images that are culturally rich and resonant, since it draws on shared symbols and imagination. The downside is it might unconsciously reinforce the biases or assumptions of our cultural narratives (for example, if one always imagines certain roles or appearances in a "hero" or "village," those biases carry into the image). The <span class="system-text">system approach</span>, by contrast, lets you specify exactly what you want represented - giving precision and the possibility to correct or include details (you can deliberately add diversity or specific elements). However, it may yield images that feel cookie-cutter or context-less if one relies too much on generic technical prompts (e.g., many AI images end up looking similar when everyone uses the same tags like "8K, UHD, ultra-detailed").</li>
                        <li><strong>Reproducibility:</strong> A <span class="ritual-text">ritual-esque prompt</span> is great for exploration - each result might be a fresh take (which is good in creative contexts). But if you need to reproduce the exact image or verify results, it's difficult; there's an unpredictability. The <span class="system-text">system approach</span> shines here: by using the same seed and parameters, you or others can generate the same image again, which is important for scientific or archival purposes. The flip side is that focusing on reproducibility can limit creativity ‚Äì you might stick to safe parameter presets and get less surprise or innovation in outcomes.</li>
                        <li><strong>Power dynamics:</strong> <span class="ritual-text">Ritual framing</span> is <span class="ritual-text">inclusive</span> in that it uses natural language and storytelling - you don't need specialized knowledge to start (anyone who can write can try prompting). That empowers a broad base of users as narrators. But the risk is that the actual power of the system (the algorithm, the training data) is somewhat hidden behind the "magic" of natural language. Users might not realize how the system is biasing or shaping results. In contrast, the <span class="system-text">system approach</span> makes the mechanism more explicit: it encourages understanding the tool (model versions, settings) - which can be empowering for those who learn it. Yet, this expertise requirement can create a <span class="system-text">barrier</span>: power concentrates in the hands of those who have the technical know-how or control the software/hardware. It can also create a mindset where we see the images as just outputs of a machine, possibly ignoring the human meaning or ethical side.</li>
                        <li><strong>Provenance:</strong> One notable point - if we care about accountability and transparency (say, in journalism or academic use of AI images), the <span class="system-text">system approach</span> is beneficial because you can log the exact prompt, model, and seed used to generate an image, establishing provenance. The <span class="ritual-text">ritual approach</span> might not encourage that level of detail in record-keeping.</li>
                    </ul>
                    <p>In summary, neither approach is "all good" or "all bad." We need to balance them: use the social, meaningful richness of ritual framing and the precision and transparency of system controls. Being aware of these trade-offs helps us mitigate risks (like bias or exclusivity) while harnessing the benefits (like creativity and reproducibility).</p>
                </div>
            </div>
        </div>

        <!-- Slide 13: Discussion -->
        <div class="slide" id="discussion">
            <div class="slide-content-wrapper">
                <h2>Discussion</h2>
                <div class="image-placeholder-container">
                    <span class="icon icon-question" style="width: 8em; height: 8em; color: var(--accent-color);"></span>
                    <p class="visual-description"><strong>Visual:</strong> A question mark icon in the center, with speech bubbles around it showing snippets of these questions ‚Äì inviting open discussion.</p>
                    <p class="alt-text"><strong>ALT TEXT:</strong> A big question mark surrounded by the key discussion questions: ritual vs control, agency in AI (humans or machines), and how to teach prompting (creative vs technical).</p>
                    <p class="image-url-tip"><em>This visual is a conceptual icon, implemented directly in HTML/CSS/SVG.</em></p>
                </div>
                <ul>
                    <li>Does treating prompts as <span class="ritual-text">ritual</span> improve their meaning, or does it hide who/what is really in control?</li>
                    <li>Where do you think <span class="ritual-text">agency</span> lives in AI image-making ‚Äì with the community of users and their cultural inputs, or in the technical stacks and algorithms?</li>
                    <li>How should we teach and learn prompting skills? More like an art of rhetoric and storytelling, as a technical coding skill, or a mix of both?</li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> Now let's open up for discussion. We have a few provocative questions to consider:</p>
                    <ul>
                        <li><strong>Ritual vs Control:</strong> If we frame the act of prompting as a kind of cultural ritual (full of narrative and meaning), does that help us get more meaningful results ‚Äì or does it possibly obscure the fact that a machine is doing the work under the hood? For instance, when you write a flowery prompt and get a beautiful image, do you feel more connected to the result? Conversely, might that narrative framing make us forget about dataset biases or hidden model processes? Let's discuss experiences or thoughts on whether emphasizing ritual meaning enhances or masks the control of the system.</li>
                        <li><strong>Agency - Human or Machine:</strong> Think about who (or what) is really the driving force in AI media generation. Is it the community of prompters, artists, and viewers (a very Carey-like, human-centered view)? Or is it the algorithms, models, and data that dictate what images appear (a Kittler-like, machine-driven view)? Perhaps it's a feedback loop of both - but where do you see the center of gravity right now? Do the tools shape our imaginations (e.g., trending aesthetics that the AI is good at), or do our cultural imaginations shape what the tools produce?</li>
                        <li><strong>Teaching Prompting - Rhetoric or Engineering:</strong> If you were teaching someone to be great at using AI image generators, would you focus on <span class="ritual-text">rhetorical skills</span> (choosing evocative words, crafting a scene ‚Äì akin to creative writing) or on <span class="system-text">technical skills</span> (knowing the right parameters, model versions, and syntax ‚Äì akin to programming)? Or is the real skillset a hybrid? This touches on whether prompting is more of an art or a science, and how we can incorporate both approaches in education and practice. Feel free to also bring up any other questions or reflections ‚Äì for example, something that surprised you in the session, or an ethical dilemma you foresee with these approaches. Let's have 10 minutes of open discussion around these points (you can address whichever question resonates most with you).</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 14: Synthesis & Takeaways -->
        <div class="slide" id="takeaways">
            <div class="slide-content-wrapper">
                <h2>Synthesis & Takeaways</h2>
                <ul>
                    <li><strong>Media as Ritual:</strong> They script social belonging and shared meaning (a communal ‚Äúdance").</li>
                    <li><strong>Media as System:</strong> They script possibilities and limits (the technical "rules of the game").</li>
                    <li><strong>Operative Ekphrasis = Convergence:</strong> AI prompts unite ritual and system ‚Äì social language used as a technical procedure.</li>
                    <li><strong>Next Prompt Habit:</strong> Mix a cultural cue and a technical tweak in your text-to-image prompt.
                        <div class="venn-diagram-container">
                            <span class="icon icon-venn" style="width: 3em; height: 3em; color: var(--accent-color); margin-bottom: 10px;"></span>
                            <div class="venn-diagram">
                                <div class="circle ritual"><span>Ritual (Culture)</span></div>
                                <div class="circle system"><span>System (Tech)</span></div>
                                <div class="overlap-text">Operative Prompt (AI Prompt)</div>
                            </div>
                            <p class="visual-description" style="margin-top: 20px;"><strong>Visual:</strong> A Venn diagram with one circle "Ritual (Culture)" and the other "System (Tech)" overlapping; in the overlap is "Operative Prompt". A small tip icon highlights a note about combining both in practice.</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> Venn diagram showing ‚ÄúRitual‚Äù on one side and "System" on the other, overlapping in the middle labeled "Operative Ekphrasis (AI Prompt)." Below is a tip: "Use both cultural context and technical controls in your next prompt."</p>
                            <p class="image-url-tip"><em>This visual is conceptual and implemented directly in HTML/CSS/SVG.</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> Let's wrap up with a few key takeaways:</p>
                    <ul>
                        <li><strong>Ritual view of media:</strong> Think of media (whether it's newspapers, TV, or AI generators) as rituals that script how we belong. This view (courtesy of Carey) reminds us that every time we engage with media, we might be participating in a social ceremony - reaffirming values, identities, and relationships. For example, a group chat filled with memes can be a ritual that bonds friends daily. Media in this sense tell us who we are together. That's the power of the communal script.</li>
                        <li><strong>System view of media:</strong> At the same time, media are technical systems that script what is possible. Kittler's perspective teaches us that behind every message is a machine (or code or infrastructure) defining the rules. The camera can only capture what the lens and sensor allow; the AI model can only generate what its training data encompasses. Media set the parameters of our communication. Being aware of this "rules of the game" aspect means we can better understand limitations and harness capabilities.</li>
                        <li><strong>Operative Ekphrasis ‚Äì where ritual meets system:</strong> In AI prompting, these two come together. When you write a prompt, you're using human language (full of cultural context, connotations, imagination) but you're also programming a system (following a format, triggering algorithms). This operative ekphrasis is literally writing with the intention to operate a machine. It's a beautiful hybrid: part creative expression, part technical command. Finally, an actionable habit for you: <span class="system-text">Mix both approaches in your next prompt</span>. For example, include a little cultural or stylistic cue that speaks to meaning and include a concrete technical or visual detail to guide the system. If you want a portrait that feels nostalgic, don't just say "nostalgic" (cultural mood), maybe also specify "film grain, 1970s photo‚Äù (technical detail that produces nostalgia). If you want an epic scene (ritual grandeur), also consider something like "panoramic view, 4K resolution" (system clarity). By consciously blending the ritual and the system in your practice, you'll become a more thoughtful and effective media creator in the age of AI.</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 15: Bibliography -->
        <div class="slide" id="bibliography">
            <div class="slide-content-wrapper">
                <h2>Bibliography</h2>
                <ol class="bibliography">
                    <li id="ref-1">James W. Carey - "A Cultural Approach to Communication" (Communication as Culture, 1989).</li>
                    <li id="ref-2">Carey, James W. (1989). ‚ÄúA Cultural Approach to Communication.‚Äù In Communication as Culture: Essays on Media and Society. An essay distinguishing the ritual and transmission views of communication, using examples like religion and the news.</li>
                    <li id="ref-3">Carey, James W. (1989). ‚ÄúA Cultural Approach to Communication.‚Äù In Communication as Culture: Essays on Media and Society. An essay distinguishing the ritual and transmission views of communication, using examples like religion and the news.</li>
                    <li id="ref-4">Friedrich A. Kittler ‚Äì Gramophone, Film, Typewriter (Stanford University Press, 1999). Kittler, Friedrich A. (1986 German, trans. 1999). Gramophone, Film, Typewriter. Stanford University Press. A seminal book arguing that the devices of recording and communication fundamentally structure discourse; includes Kittler's famous maxim "Media determine our situation."</li>
                    <li id="ref-5">Friedrich Kittler (1943-2011) - News/Research - Berkeley Center for New Media <a href="https://bcnm.berkeley.edu/news-research/2270/friedrich-kittler-1943-2011" target="_blank">https://bcnm.berkeley.edu/news-research/2270/friedrich-kittler-1943-2011</a></li>
                    <li id="ref-6">Friedrich Kittler (1943-2011) - News/Research - Berkeley Center for New Media <a href="https://bcnm.berkeley.edu/news-research/2270/friedrich-kittler-1943-2011" target="_blank">https://bcnm.berkeley.edu/news-research/2270/friedrich-kittler-1943-2011</a></li>
                    <li id="ref-7">Friedrich Kittler (1943-2011) - News/Research - Berkeley Center for New Media <a href="https://bcnm.berkeley.edu/news-research/2270/friedrich-kittler-1943-2011" target="_blank">https://bcnm.berkeley.edu/news-research/2270/friedrich-kittler-1943-2011</a></li>
                    <li id="ref-8">Hannes Bajohr ‚Äì "Operative Ekphrasis: The Collapse of the Text/Image Distinction in Multimodal AI" (2024). Bajohr, Hannes. (2024). "Operative Ekphrasis: The Collapse of the Text/Image Distinction in Multimodal AI." Word & Image, 40(1). Introduces the concept of operative ekphrasis to describe how AI prompts turn text into images, blurring creation and description.</li>
                    <li id="ref-9">John Keats - "Ode on a Grecian Urn" (1820). Keats, John. (1820). "Ode on a Grecian Urn." A poem in which the speaker contemplates the eternal scenes on an ancient urn; a classic example of ekphrasis (poetic description of visual art).</li>
                    <li id="ref-10">Guillaume Apollinaire ‚Äì "The Poet Who Painted with Words" (Calligrammes, 1918). Apollinaire, Guillaume. (1918). "The Poet Who Painted with Words." In Calligrammes: Poems of Peace and War. Apollinaire's collection featuring calligrammes (poems in which text layout creates a visual image), bridging poetry and visual art.</li>
                    <li id="ref-11">Modernity Student Reader <a href="https://files.romanroadsstatic.com/uploads/2016/06/Modernity-Student-Reader.pdf" target="_blank">https://files.romanroadsstatic.com/uploads/2016/06/Modernity-Student-Reader.pdf</a></li>
                    <li id="ref-12">Jack Wild - Say What You See (Google Arts & Culture experiment, 2023). Say What You See: This Google game will give you AI power! Learn how to write image prompts | How-to <a href="https://tech.hindustantimes.com/how-to/say-what-you-see-this-google-game-will-give-you-ai-power-learn-how-to-write-image-prompts-71703746713382.html" target="_blank">https://tech.hindustantimes.com/how-to/say-what-you-see-this-google-game-will-give-you-ai-power-learn-how-to-write-image-prompts-71703746713382.html</a></li>
                    <li id="ref-13">Prompt Structure for AI Image Generation - Experiencing Elearning <a href="https://christytuckerlearning.com/prompt-structure-for-ai-image-generation/" target="_blank">https://christytuckerlearning.com/prompt-structure-for-ai-image-generation/</a></li>
                </ol>
                <p class="notes"><strong>Visual:</strong> N/A (text-only slide for references).</p>
                <p class="alt-text"><strong>ALT TEXT:</strong> N/A.</p>
            </div>
        </div>

        <!-- Slide 16: Appendix: Carey vs. Kittler Matrix (Detailed) -->
        <div class="slide" id="appendix-detailed-matrix">
            <div class="slide-content-wrapper">
                <h2>Appendix: Carey vs. Kittler Matrix (Detailed)</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Comparison</th>
                            <th class="ritual-header">Carey - Ritual View</th>
                            <th class="system-header">Kittler - Material View</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Unit of Analysis</td>
                            <td class="ritual-column">Symbolic acts & Rituals:<br>Communication is studied as cultural practices, ceremonies, shared narratives within a community.</td>
                            <td class="system-column">Media Apparatus: Analysis centers on physical media technologies and their formats (the "discourse networks" of hardware/software).</td>
                        </tr>
                        <tr>
                            <td>Causality</td>
                            <td class="ritual-column">Meaning <-> Society:<br>Communication rituals both emerge from and reinforce social beliefs. Causal influence is looped through culture (not strictly one-way).</td>
                            <td class="system-column">Technical Determinism: The capabilities of media devices (storage, transmission) directly shape what can be communicated; technology is the prime mover.</td>
                        </tr>
                        <tr>
                            <td>Temporality</td>
                            <td class="ritual-column">Time-binding & Cyclical:<br>Media (as rituals) operate in repetitive time - e.g., daily news ritual sustains continuity of a community's worldview.</td>
                            <td class="system-column">Historical/Linear: Media technologies mark distinct eras (e.g., print era vs. digital era). New inventions disrupt continuity and create a linear progression of epochs.</td>
                        </tr>
                        <tr>
                            <td>Agency</td>
                            <td class="ritual-column">Human-Centric: Emphasis on human agency - senders, receivers, and participants actively create and interpret meaning. Media are tools imbued with cultural intent.</td>
                            <td class="system-column">Machine-Centric: Agency lies with media systems - "the machine" processes information in its own manner. Humans become adapters or operands of media operations.</td>
                        </tr>
                    </tbody>
                </table>
                <div class="notes">
                    <p><strong>ALT TEXT:</strong> Expanded table comparing the two theorists: Carey focuses on culture and human meanings (rituals), Kittler focuses on technology and non-human forces (machines).</p>
                    <p><strong>Notes:</strong> This detailed matrix provides a side-by-side reference of James Carey's <span class="ritual-text">ritual view</span> versus Friedrich Kittler's <span class="system-text">materialist media theory</span>. Use this to recall how each answers fundamental questions about communication:</p>
                    <ul>
                        <li><strong>- What do we analyze?</strong> Carey looks at <span class="ritual-text">ritual acts</span> (like watching TV news as a social ceremony), whereas Kittler looks at <span class="system-text">media machines and formats</span> (like the technical setup of a television and its signal).</li>
                        <li><strong>- What causes what?</strong> Carey sees a <span class="ritual-text">circular causality</span> between communication and culture ‚Äì our shared beliefs shape media rituals, and those rituals in turn maintain the beliefs. Kittler proposes a more <span class="system-text">one-directional causality</span> from technology ‚Äì for example, once the phonograph was invented, it changed music and memory in ways independent of human intention.</li>
                        <li><strong>- How is time involved?</strong> Carey emphasizes how media rituals help bind a community through time by repetition (the past is continuously brought into the present through ritual). Kittler emphasizes how each new medium creates a break with the past, ushering in a new timeframe (e.g., the shift from handwritten letters to the telegraph created a new speed of communication that transformed society).</li>
                        <li><strong>- Who/what has agency?</strong> Carey's framework gives agency to <span class="ritual-text">people</span> using media (media are extensions of our social intentions). Kittler's gives a form of agency to <span class="system-text">media systems</span> themselves (we start to operate according to the logic of our tools ‚Äì e.g., we write differently on a typewriter than we would by hand).</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 17: Appendix: Descriptive vs Operative Prompt Cheat-Sheet -->
        <div class="slide" id="appendix-cheat-sheet">
            <div class="slide-content-wrapper">
                <h2>Appendix: Descriptive vs Operative Prompt Cheat-Sheet</h2>
                <div class="notes">
                    <p>Neither view alone is sufficient, but each highlights crucial aspects. In modern analysis (like AI media), we often need to consider both: the cultural practices AND the technical infrastructure.</p>
                </div>
                <ul>
                    <li><strong>Structure:</strong> <code>&lt;medium & style&gt;, &lt;subject&gt;, &lt;key attributes&gt;, &lt;context&gt;, &lt;parameters&gt;</code></li>
                    <li><strong>Descriptive Prompt (ekphrasis):</strong> ‚ÄúA couple under spring trees, reaching for a kiss, frozen in time."</li>
                    <li><strong>Operative Prompt (procedural):</strong> "Oil painting, golden-hour light, couple under trees about to kiss, highly detailed‚Äù
                        <div class="image-placeholder-container">
                            <div class="studio-exercise-visual">
                                <div class="prompt-box">
                                    <h4>Descriptive Prompt</h4>
                                    <p>"A couple under spring trees, reaching for a kiss, frozen in time."</p>
                                </div>
                                <span class="arrow">‚û°Ô∏è</span>
                                <div class="prompt-box">
                                    <h4>Operative Prompt</h4>
                                    <p>"Oil painting, golden-hour light, couple under trees about to kiss, highly detailed"</p>
                                </div>
                            </div>
                            <p class="visual-description"><strong>Visual:</strong> N/A (this visual is conceptual, similar to the studio exercise, illustrating the transformation).</p>
                            <p class="alt-text"><strong>ALT TEXT:</strong> Example transformation ‚Äì Original descriptive prompt versus an enhanced operative prompt with medium, lighting, and detail.</p>
                            <p class="image-url-tip"><em>This visual is conceptual and implemented directly in HTML/CSS.</em></p>
                        </div>
                    </li>
                </ul>
                <div class="notes">
                    <p><strong>Notes:</strong> Use this cheat-sheet to transform descriptive prompts into more <span class="system-text">operative</span> ones for AI image generation:</p>
                    <ul>
                        <li>Start by outlining the prompt structure: first specify a <span class="system-text">medium and/or style</span> (e.g. photo, watercolor, oil painting, digital 3D render), then clearly state the <span class="system-text">subject</span>, add important <span class="system-text">attributes or modifiers</span> (adjectives for appearance, mood, lighting), include any <span class="system-text">context or background setting</span>, and if needed, append <span class="system-text">technical parameters</span> (like aspect ratio, resolution, or even model/seed info if using a specific tool).</li>
                        <li><strong>Descriptive Prompt (Before):</strong> The example given is narrative and open-ended. "A couple under spring trees, reaching for a kiss, frozen in time." It paints a mental picture but doesn't tell the AI how to draw it. This is like a line from a story - rich for a human reader, but an AI might produce any number of interpretations from it.</li>
                        <li><strong>Operative Prompt (After):</strong> The revised prompt adds concrete visual instructions: ‚ÄúOil painting, golden-hour light, couple under trees about to kiss, highly detailed.‚Äù Here, "Oil painting" sets a medium/style expectation (the texture and look of the output). "Golden-hour light" gives a specific lighting and time of day (warm, soft shadows). The core subject ‚Äúcouple under trees about to kiss" is still there (we kept the essence of the scene). "Highly detailed" instructs the AI to aim for clarity and intricacy. We dropped the phrase "frozen in time" because the concept of an paused moment is now implied by the scenario and medium (and because the AI might not literally understand "frozen in time" except as maybe people covered in ice!). We could further fine-tune by adding a parameter like "-seed 42" or "4k resolution‚Äù if the platform allows, but even without that, this operative prompt is far more prescriptive than the original descriptive one.</li>
                        <li><strong>General tip:</strong> When rewriting, try to preserve the essence or emotional core of the descriptive prompt (in this case, intimacy and stillness) while adding the visual and technical cues that will guide the AI to deliver that essence in a consistent way. You can always iterate: generate an image, see what's missing or off, and refine the prompt by adding or adjusting terms in this structure.</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 18: Appendix: Prompt Versioning & Provenance Guide -->
        <div class="slide" id="appendix-provenance">
            <div class="slide-content-wrapper">
                <h2>Appendix: Prompt Versioning & Provenance Guide</h2>
                <ul>
                    <li class="checklist-item"><span><span class="icon icon-clipboard"></span><strong>Record your settings:</strong> Always note the model/version used, sampler type, and seed number for each generated image.</span></li>
                    <li class="checklist-item"><span><span class="icon icon-clipboard"></span><strong>Name iterations:</strong> Use descriptive filenames or version labels (e.g., <code>SunsetPortrait_v1.png</code>, <code>SunsetPortrait_v2_seed42.png</code>) to track changes.</span></li>
                    <li class="checklist-item"><span><span class="icon icon-clipboard"></span><strong>Keep a prompt log:</strong> Maintain a notebook or text file listing your prompt attempts, parameters, and observations on outputs.</span></li>
                    <li class="checklist-item"><span><span class="icon icon-save"></span><strong>Preserve metadata:</strong> When sharing or publishing AI-generated images, include the prompt and key settings (provenance) so others understand how it was made.</span></li>
                </ul>
                <div class="notes">
                    <p><strong>ALT TEXT:</strong> Icon of a clipboard and a save disk, representing documentation and saving of prompt parameters.</p>
                    <p><strong>Notes:</strong> Professional and reproducible practice in AI image generation involves <span class="system-text">versioning and provenance</span> ‚Äì basically, keeping track of how an image was made:</p>
                    <ul>
                        <li>Whenever you generate an image, <span class="system-text">jot down the exact prompt and parameters</span>. If you're using Stable Diffusion or similar, note which model (e.g., Stable Diffusion v1.5 or v2.1), which sampler (DDIM, Euler a, etc.), how many inference steps, the guidance scale (if applicable), and the <span class="system-text">random seed</span> if you set one (or note that you let it be random). These details are crucial if you want to get the same result again or troubleshoot differences.</li>
                        <li>It helps to <span class="system-text">name your files or versions clearly</span>. Instead of generic names, use something meaningful that reflects the prompt or the iteration. For example, add a version number or a keyword for the prompt. This way, when you look back at an image, you can trace which prompt version it came from. Some people include a short form of the seed or important settings in the filename as well.</li>
                        <li><span class="system-text">Maintain a simple prompt log</span>. This could be a spreadsheet or just a running text document where each entry has the prompt, settings, date, and results/comments. This is immensely helpful when refining prompts - you can see what you changed between v1 and v2 and what effect it had.</li>
                        <li><span class="system-text">Metadata and sharing:</span> If you plan to publish the image (say in a paper, blog, or art portfolio), consider including the prompt or even a snippet of the metadata in the caption or appendix. In the AI art community, it's common to share the prompt and settings so others can learn or even replicate. For instance, on some platforms, images carry metadata that includes the prompt and model automatically ‚Äì try to keep that metadata when possible.</li>
                        <li>This practice isn't just about personal organization ‚Äì it's about <span class="system-text">transparency</span>. In scientific contexts, it's akin to sharing your experimental method. In art, it can be an educational insight into your process. And ethically, provenance helps combat misinformation (people can see an image was AI-generated and how).</li>
                        <li>Lastly, if you do a lot of prompting, consider using version control tools (some advanced users adapt Git or other tracking for prompts) or specialized prompt management apps. But even a well-structured Google Doc can do wonders for keeping your prompt experiments orderly.</li>
                    </ul>
                </div>
                <p>(Exit Ticket: As we conclude, take one minute to write down one ‚Äúritual‚Äù element and one "system‚Äù constraint you plan to be mindful of in your next AI prompt. For example, you might note ‚ÄúRitual: consider cultural context of images (e.g., avoid clich√©s) | System: fix a seed to recreate results.")</p>
                <div class="json-block">
                    <pre><code>{
"course_session": "S6",
"title": "The Medium as Operator",
"date": "Thu 09/04",
"length_min": 75,
"slides_planned": 15,
"accent_color": "#111111",
"objectives": [
"Compare Carey vs Kittler",
"Define operative ekphrasis",
"Apply theory to AI text‚Äìimage",
"Practice prompt rewriting"
]
}</code></pre>
                </div>
            </div>
        </div>

        <div class="nav-zone left" aria-hidden="true" title="Previous slide"></div>
        <div class="nav-zone right" aria-hidden="true" title="Next slide"></div>

        <div class="controls-panel" role="group" aria-label="Slide controls">
            <input type="url" id="img-url-input" placeholder="Paste image URL and click Apply ‚Üí" inputmode="url" />
            <button class="mini-btn" id="apply-img-btn" title="Apply to selected image">Apply</button>
            <div class="divider" aria-hidden="true"></div>
            <button class="mini-btn" id="prev-img-btn" title="Select previous image on this slide">‚óÇ Img</button>
            <button class="mini-btn" id="next-img-btn" title="Select next image on this slide">Img ‚ñ∏</button>
            <div class="divider" aria-hidden="true"></div>
            <button class="mini-btn" id="copy-alt-btn" title="Copy ALT TEXT for selected image">Copy ALT</button>
            <button class="mini-btn" id="copy-visual-btn" title="Copy Visual Description for selected image">Copy Visual</button>
            <div class="divider" aria-hidden="true"></div>
            <label title="Show speaker notes (N)"><input type="checkbox" id="toggle-notes"> Show notes</label>
        </div>

        <div class="slide-footer">
            <button class="nav-btn" id="prev-btn" aria-label="Previous slide">‚Üê Prev</button>
            <div class="footer-center">
                <span id="slide-number"></span>
                <span class="hint">Use ‚Üê / ‚Üí keys</span>
                <div class="progress-bar" aria-hidden="true"><div class="progress" id="progress"></div></div>
            </div>
            <button class="nav-btn" id="next-btn" aria-label="Next slide">Next ‚Üí</button>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const slides = document.querySelectorAll('.slide');
            const slideNumberSpan = document.getElementById('slide-number');
            const prevBtn = document.getElementById('prev-btn');
            const nextBtn = document.getElementById('next-btn');
            const progressEl = document.getElementById('progress');
            const leftZone = document.querySelector('.nav-zone.left');
            const rightZone = document.querySelector('.nav-zone.right');
            const imgUrlInput = document.getElementById('img-url-input');
            const applyImgBtn = document.getElementById('apply-img-btn');
            const prevImgBtn = document.getElementById('prev-img-btn');
            const nextImgBtn = document.getElementById('next-img-btn');
            const toggleNotes = document.getElementById('toggle-notes');
            const copyAltBtn = document.getElementById('copy-alt-btn');
            const copyVisualBtn = document.getElementById('copy-visual-btn');

            // Map slide IDs to indices for hash routing
            const slideIndexById = new Map(Array.from(slides).map((s, i) => [s.id, i]));

            // Determine initial slide from URL hash if present
            const initialHash = (location.hash || '').replace('#', '');
            let currentSlideIndex = slideIndexById.has(initialHash) ? slideIndexById.get(initialHash) : 0;

            // Update bibliography superscript links to point to specific slide IDs
            slides.forEach(slide => {
                slide.querySelectorAll('sup[id$="-back"]').forEach(sup => {
                    const refId = sup.id.replace('-back', '');
                    const refElement = document.getElementById(refId);
                    if (refElement) {
                        sup.querySelector('a').href = `#${refId}`;
                    }
                });
            });

            const updateHashQuietly = (id) => {
                if ('replaceState' in history) {
                    history.replaceState(null, '', `#${id}`);
                } else {
                    location.hash = `#${id}`;
                }
            };

            // Track selected image index per slide
            const selectedImgIndexBySlide = new Map();

            const getImagesOnSlide = (index) => Array.from(slides[index]?.querySelectorAll('img.image-placeholder') || []);

            const selectImageOnSlide = (index, imgIndex = 0) => {
                const imgs = getImagesOnSlide(index);
                imgs.forEach(img => img.classList.remove('selected'));
                if (imgs.length === 0) return null;
                const bounded = Math.max(0, Math.min(imgIndex, imgs.length - 1));
                imgs[bounded].classList.add('selected');
                selectedImgIndexBySlide.set(index, bounded);
                return imgs[bounded];
            };

            // Helpers to locate text near the selected image
            const getSelectedImage = () => {
                const imgs = getImagesOnSlide(currentSlideIndex);
                if (imgs.length === 0) return null;
                const selIdx = selectedImgIndexBySlide.get(currentSlideIndex) ?? 0;
                return imgs[Math.max(0, Math.min(selIdx, imgs.length - 1))] || null;
            };

            const getImageContainer = (imgEl) => imgEl?.closest('.image-placeholder-container') || imgEl?.closest('.slide');

            const extractText = (el, selector, stripPrefixRegex) => {
                if (!el) return '';
                const t = el.querySelector(selector)?.textContent?.trim() || '';
                if (!t) return '';
                return stripPrefixRegex ? t.replace(stripPrefixRegex, '').trim() : t;
            };

            const copyToClipboard = async (text) => {
                try {
                    if (!text) return false;
                    if (navigator.clipboard && navigator.clipboard.writeText) {
                        await navigator.clipboard.writeText(text);
                        return true;
                    }
                    // Fallback
                    const ta = document.createElement('textarea');
                    ta.value = text;
                    ta.setAttribute('readonly', '');
                    ta.style.position = 'absolute';
                    ta.style.left = '-9999px';
                    document.body.appendChild(ta);
                    ta.select();
                    const ok = document.execCommand('copy');
                    document.body.removeChild(ta);
                    return ok;
                } catch (e) {
                    return false;
                }
            };

            const withCopiedFeedback = async (btn, fn) => {
                if (!btn) return;
                const original = btn.textContent;
                const ok = await fn();
                btn.textContent = ok ? 'Copied!' : 'Nothing to copy';
                setTimeout(() => { btn.textContent = original; }, 1200);
            };

            // Select a specific image element on the current slide and sync state
            const selectImageElementOnSlide = (slideIdx, imgEl) => {
                if (!imgEl || slideIdx < 0) return;
                const imgs = getImagesOnSlide(slideIdx);
                imgs.forEach(i => i.classList.remove('selected'));
                imgEl.classList.add('selected');
                const globalIdx = imgs.indexOf(imgEl);
                if (globalIdx >= 0) selectedImgIndexBySlide.set(slideIdx, globalIdx);
            };

            // Initialize per-container carousels where multiple images exist
            const setupCarousels = () => {
                document.querySelectorAll('.image-placeholder-container').forEach(container => {
                    const imgs = Array.from(container.querySelectorAll('img.image-placeholder'));
                    if (imgs.length > 1) {
                        container.classList.add('is-carousel');
                        // Ensure one selected within this container
                        let selected = imgs.find(i => i.classList.contains('selected'));
                        if (!selected) {
                            selected = imgs[0];
                            selected.classList.add('selected');
                        }
                        // Inject nav buttons if not present
                        if (!container.querySelector('.carousel-nav.prev')) {
                            const prev = document.createElement('button');
                            prev.type = 'button';
                            prev.className = 'carousel-nav prev';
                            prev.setAttribute('aria-label', 'Previous image');
                            prev.textContent = '‚Äπ';
                            const next = document.createElement('button');
                            next.type = 'button';
                            next.className = 'carousel-nav next';
                            next.setAttribute('aria-label', 'Next image');
                            next.textContent = '‚Ä∫';

                            const cycle = (dir) => {
                                const curImgs = Array.from(container.querySelectorAll('img.image-placeholder'));
                                let curIndex = curImgs.findIndex(i => i.classList.contains('selected'));
                                if (curIndex < 0) curIndex = 0;
                                const newIndex = (curIndex + dir + curImgs.length) % curImgs.length;
                                curImgs.forEach(i => i.classList.remove('selected'));
                                const nextImg = curImgs[newIndex];
                                nextImg.classList.add('selected');
                                // Sync with slide selection state
                                const slideEl = container.closest('.slide');
                                const slideIdx = Array.from(slides).indexOf(slideEl);
                                if (slideIdx !== -1) selectImageElementOnSlide(slideIdx, nextImg);
                            };

                            prev.addEventListener('click', (e) => { e.preventDefault(); cycle(-1); });
                            next.addEventListener('click', (e) => { e.preventDefault(); cycle(1); });
                            container.appendChild(prev);
                            container.appendChild(next);
                        }
                    }
                });
            };

            const showSlide = (index) => {
                slides.forEach((slide, i) => {
                    slide.classList.remove('active');
                    if (i === index) {
                        slide.classList.add('active');
                        slide.scrollTop = 0; // Reset scroll position for new slide
                    }
                });
                slideNumberSpan.textContent = `Slide ${index + 1} of ${slides.length}`;
                const pct = ((index + 1) / slides.length) * 100;
                if (progressEl) progressEl.style.width = `${pct}%`;
                if (prevBtn) prevBtn.disabled = index === 0;
                if (nextBtn) nextBtn.disabled = index === slides.length - 1;
                const currentId = slides[index]?.id;
                if (currentId) updateHashQuietly(currentId);
                // Update document title with current slide heading for context
                const h = slides[index]?.querySelector('h1, h2');
                if (h) document.title = `${h.textContent.trim()} ‚Äî The Medium as Operator`;

                // Initialize image selection for this slide
                const startIdx = selectedImgIndexBySlide.get(index) ?? 0;
                selectImageOnSlide(index, startIdx);
            };

            const nextSlide = () => {
                currentSlideIndex = Math.min(currentSlideIndex + 1, slides.length - 1);
                showSlide(currentSlideIndex);
            };

            const prevSlide = () => {
                currentSlideIndex = Math.max(currentSlideIndex - 1, 0);
                showSlide(currentSlideIndex);
            };

            // Click navigation (buttons and zones)
            prevBtn?.addEventListener('click', (e) => { e.preventDefault(); prevSlide(); });
            nextBtn?.addEventListener('click', (e) => { e.preventDefault(); nextSlide(); });
            leftZone?.addEventListener('click', (e) => { if (e.target === leftZone) prevSlide(); });
            rightZone?.addEventListener('click', (e) => { if (e.target === rightZone) nextSlide(); });

            // Image selection by click
            document.addEventListener('click', (e) => {
                const img = e.target.closest('img.image-placeholder');
                if (!img) return;
                const slideEl = img.closest('.slide');
                const index = Array.from(slides).indexOf(slideEl);
                if (index === -1) return;
                const imgs = getImagesOnSlide(index);
                const imgIndex = imgs.indexOf(img);
                selectImageOnSlide(index, imgIndex);
            });

            // Apply image URL to selected image
            const applyUrlToSelected = () => {
                const url = (imgUrlInput?.value || '').trim();
                if (!url) return;
                const imgs = getImagesOnSlide(currentSlideIndex);
                if (imgs.length === 0) return;
                const selIdx = selectedImgIndexBySlide.get(currentSlideIndex) ?? 0;
                const target = imgs[selIdx] || imgs[0];
                target.src = url;
            };
            applyImgBtn?.addEventListener('click', (e) => { e.preventDefault(); applyUrlToSelected(); });
            imgUrlInput?.addEventListener('keydown', (e) => { if (e.key === 'Enter') { e.preventDefault(); applyUrlToSelected(); }});
            prevImgBtn?.addEventListener('click', (e) => {
                e.preventDefault();
                const imgs = getImagesOnSlide(currentSlideIndex);
                if (imgs.length === 0) return;
                const selIdx = (selectedImgIndexBySlide.get(currentSlideIndex) ?? 0) - 1;
                selectImageOnSlide(currentSlideIndex, selIdx);
            });
            nextImgBtn?.addEventListener('click', (e) => {
                e.preventDefault();
                const imgs = getImagesOnSlide(currentSlideIndex);
                if (imgs.length === 0) return;
                const selIdx = (selectedImgIndexBySlide.get(currentSlideIndex) ?? 0) + 1;
                selectImageOnSlide(currentSlideIndex, selIdx);
            });

            // Copy ALT and Visual Description handlers
            copyAltBtn?.addEventListener('click', (e) => {
                e.preventDefault();
                withCopiedFeedback(copyAltBtn, async () => {
                    const img = getSelectedImage();
                    const container = getImageContainer(img);
                    const text = extractText(container, '.alt-text', /^ALT\s*TEXT:\s*/i);
                    return copyToClipboard(text);
                });
            });
            copyVisualBtn?.addEventListener('click', (e) => {
                e.preventDefault();
                withCopiedFeedback(copyVisualBtn, async () => {
                    const img = getSelectedImage();
                    const container = getImageContainer(img);
                    const text = extractText(container, '.visual-description', /^Visual:\s*/i);
                    return copyToClipboard(text);
                });
            });

            // Keyboard navigation
            document.addEventListener('keydown', (event) => {
                const k = event.key;
                if (k === 'ArrowRight' || k === 'PageDown' || k === ' ' || k === 'Enter') {
                    event.preventDefault();
                    nextSlide();
                } else if (k === 'ArrowLeft' || k === 'PageUp' || (k === ' ' && event.shiftKey)) {
                    event.preventDefault();
                    prevSlide();
                } else if (k === 'Home') {
                    event.preventDefault();
                    currentSlideIndex = 0; showSlide(currentSlideIndex);
                } else if (k === 'End') {
                    event.preventDefault();
                    currentSlideIndex = slides.length - 1; showSlide(currentSlideIndex);
                } else if (k === 'n' || k === 'N') {
                    // Toggle notes visibility
                    document.body.classList.toggle('show-notes');
                    if (toggleNotes) toggleNotes.checked = document.body.classList.contains('show-notes');
                }
            });

            // Respond to manual hash changes
            window.addEventListener('hashchange', () => {
                const id = (location.hash || '').replace('#', '');
                if (slideIndexById.has(id)) {
                    currentSlideIndex = slideIndexById.get(id);
                    showSlide(currentSlideIndex);
                }
            });

            // Initial load
            setupCarousels();
            showSlide(currentSlideIndex);

            // Initialize notes checkbox state
            toggleNotes?.addEventListener('change', () => {
                document.body.classList.toggle('show-notes', toggleNotes.checked);
            });
        });
    </script>
</body>
</html>
